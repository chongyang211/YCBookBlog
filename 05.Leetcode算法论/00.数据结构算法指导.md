# 00.数据结构算法指导
#### 目录介绍
- 01.为何要复杂度分析
  - 1.1 复杂度分析好处
  - 1.2 复杂度分析原因
  - 1.3 对数和指数
- 02.算法分析基础概念
  - 2.1 时间复杂度
  - 2.2 空间复杂度
- 03.大O复杂度表示法
  - 3.1 先分析两个案例
  - 3.2 总结案例的规律
- 04.什么是时间复杂度
  - 4.1 时间复杂度介绍
  - 4.2 复杂度分析方法
  - 4.3 时间复杂度分类
  - 4.4 常数O(1)案例
  - 4.5 线性O(N)案例
  - 4.6 平方O(N^2)案例
  - 4.7 对数O(logN)案例
  - 4.8 指数O(2^N)案例
  - 4.9 线性对数O(NlogN)
- 05.什么是空间复杂度
  - 5.1 空间复杂度介绍
  - 5.2 空间复杂度定义
  - 5.3 暂存空间指什么
  - 5.4 符号表示的含义
  - 5.5 常数O(1)案例
  - 5.6 线性O(N)案例
  - 5.7 平方O(N^2)案例
  - 5.8 指数O(2^N)案例
  - 5.9 对数O(logN)案例
- 06.最好和最坏分析
  - 6.1 复杂度分析概念
  - 6.2 最好情况复杂度
  - 6.3 最坏情况复杂度
  - 6.4 平均情况复杂度
  - 6.5 均摊情况复杂度
- 07.时间和空间权衡


## 01.为何要复杂度分析

### 1.1 复杂度分析好处

把代码跑一遍，通过统计、监控，就能得到算法执行的时间和占用的内存大小。为什么还要做时间、空间复杂度分析呢？

首先肯定的说，这种评估算法执行效率的方法是正确的。很多书籍管这种方法叫“事后统计法”。但是这种方法有很大的局限性：

1. 测试结果非常依赖测试环境：如测试环境中的硬件对测试结果影响很大。
2. 测试结果受数据规模的影响很大。如小规模的数据，插入排序反而比快速排序快。 

使用复杂度分析有什么好处？

复杂度分析是一种评估算法性能和效率的方法。它的目的是帮助开发人员了解算法在不同输入规模下的运行时间和空间消耗。不用具体数据来测试，就可以粗略的估算执行效率的方法。

### 1.2 复杂度分析原因

复杂度分析对于评估算法性能、预测行为、优化算法、以及推动算法改进和创新都非常重要。

1. 性能比较：复杂度分析允许开发人员比较不同算法的性能。通过分析算法的时间复杂度和空间复杂度，可以确定哪个算法在给定的输入规模下更高效。
2. 预测算法行为：复杂度分析可以帮助开发人员预测算法在不同输入规模下的行为。
3. 优化算法：复杂度分析可以帮助开发人员识别算法中的瓶颈和低效之处。
4. 算法改进和创新：复杂度分析可以激发算法改进和创新的灵感。提出更高效的解决方案。

### 1.3 对数和指数

什么是对数：在数学中，对数是对求幂的逆运算，正如除法是乘法的倒数，反之亦然。这意味着一个数字的对数是必须产生另一个固定数字（基数）的指数。在简单的情况下，乘数中的对数计数因子。更一般来说，乘幂允许将任何正实数提高到任何实际功率，总是产生正的结果，因此可以对于b不等于1的任何两个正实数b和x计算对数。

如果a的x次方等于N（a>0，且a≠1），那么数x叫做以a为底N的对数（logarithm），记作x=logaN。读作以a为底N的对数，a叫做对数的底数，N叫做真数。

一般地，函数y=logaX（a>0，且a≠1）叫做对数函数，也就是说以幂（真数）为自变量，指数为因变量，底数为常量的函数，叫对数函数。

其中x是自变量，函数的定义域是（0，+∞），即x>0。它实际上就是指数函数的反函数，可表示为x=ay。因此指数函数里对于a的规定，同样适用于对数函数。

通常我们将以10为底的对数叫常用对数（common logarithm），并把log10N记为lgN。另外，在科学计数中常使用以无理数e=2.71828···为底数的对数，以e为底的对数称为自然对数（natural logarithm），并且把logeN 记为In N。

根据对数的定义，可以得到对数与指数间的关系：当a>0，a≠1时，a^X=N <--> X=logaN。（N>0）。在实数范围内，负数和零没有对数；loga1，log以a为底1的对数为0（a为常数） 恒过点（1，0）。

## 02.算法分析基础概念

### 2.1 时间复杂度


### 2.2 空间复杂度


### 2.3 最坏情况复杂度


### 2.4 最好情况复杂度


### 2.5 平均情况复杂度



## 03.大O复杂度表示法

### 3.1 先分析两个案例

算法的执行效率，粗略的讲，就是算法的执行时间。

**案例1：这里有段简单的代码，求1到n的累加和**。

```c
int cla(int n){
    int sum = 0;
    for (int i=1 ;i<=n; i++){
        sum = sum + 1;
    }
    return sum;
}
```

现在我们来估算下，上述代码的执行时间：尽管每行代码对应cpu执行的个数、执行的时间都不一样，但是我们这里只是粗略的估计，所以我们可以假设每行代码执行的时间都一样，都为unit_time。在这个假设的基础上，我们进行分析！

第2、3行都执行了一次，第4、5行都执行了n次。所以这段代码总执行 2 * unit_time + 2n * unit_time。可以看出代码的执行时间（T(n)）与代码的执行次数成正比。

**案例2：打印9*9乘法表**。

```c
int cal(int n){
    int sum = 0;
    int i = 9; 
    int j = 9;
    for(; i<= n ;i++){
        j = 1;
        for(; j <= n ; j++){
            sum = sum + i*j;
        }
    }
}
```

进行分析。 2、3、4 行代码分别需要 1 个 unit_time 的执行时间，第 5、6 行都运行了 n 遍，所以需要 2n * unit_time 的执行时间，第 7、8 行代码循环执行了 n^2遍，所以需要 2n^2 * unit_time 的执行时间。

所以，整段代码总的执行时间 T(n) = (2n^2+2n+3) * unit_time。

通过两个例子，我们可以得出一个规律：所有代码的执行时间T(n)与每行代码的执行次数n成正比。

### 3.2 总结案例的规律

> 可以把这个规律总结成一个公式。注意，大 O 就要登场了！

T(n)=O(f(n))，来解释一下这个公式。T(n)表示代码的执行时间；n表示数据规模的大小；f(n)表示每行代码执行次数的总和。因为这是一个公式，所以用f(n)表示。公式中的O，表示代码的执行时间T(n)与f(n)表达式成正比。

> 得出结论

所以，第一个例子中Tn=O(2n+1)，第二个例子中的Tn=O(2n^2+2n+3)。这就是大O时间复杂度表示法。大O时间复杂度实际上并不代表代码的具体执行时间，而是表示代码的执行时间随数据规模增长的变化趋势，所以也叫做时间渐进复杂度（asymptotic time complexity），简称时间复杂度。

注意要点：当 n 很大时，公式中的低阶、常量、系数三部分并不左右增长趋势，所以都可以忽略。我们只需要记录一个最大量级就可以了，如果用大 O 表示法表示刚讲的那两段代码的时间复杂度，就可以记为：T(n) = O(n)； T(n) = O(n*n)。

## 04.什么是时间复杂度


### 4.1 时间复杂度介绍


### 4.2 复杂度分析方法

前面介绍了大 O 时间复杂度的由来和表示方法。现在来看下，如何分析一段代码的时间复杂度？我这儿有三个比较实用的方法。

#### 4.2.1 关注执行最多代码

刚才说了，大 O 这种复杂度表示方法只是表示一种变化趋势。我们通常会忽略掉公式中的常量、低阶、系数，只需要记录一个最大阶的量级就可以了。

所以，我们在分析一个算法、一段代码的时间复杂度的时候，也只关注循环执行次数最多的那一段代码就可以了。这段核心代码执行次数的 n 的量级，就是整段要分析代码的时间复杂度。

```c
fun sum(array: IntArray): Int {
    var total = 0             // O(1)
    for (i in array.indices) { // O(n)
        total += array[i]      // O(1)
    }
    return total               // O(1)
}
```

在上述代码中：

- var total = 0 的时间复杂度是O(1)。
- for (i in array.indices) 的循环执行了n次，时间复杂度是O(n)。
- total += array[i] 在循环中执行，每次的时间复杂度是O(1)，总的时间复杂度是O(n)。
- return total 的时间复杂度是O(1)。

总体时间复杂度是O(n)。


#### 4.2.2 加法计算时间复杂度

加法法则：总复杂度等于量级最大的那段代码的复杂度

```c
int cal(int n) {
    int sum_1 = 0;
    int p = 1;
    for (; p < 100; ++p) {
        sum_1 = sum_1 + p;
    }
    int sum_2 = 0;
    int q = 1;
    for (; q < n; ++q) {
        sum_2 = sum_2 + q;
    }
    int sum_3 = 0;
    int i = 1;
    int j = 1;
    for (; i <= n; ++i) {
        j = 1;
        for (; j <= n; ++j) {
            sum_3 = sum_3 + i * j;
        }
    }
    return sum_1 + sum_2 + sum_3;
}
```

这个代码分为三部分，分别是求 sum_1、sum_2、sum_3。

1. 第一段代码循环执行了 100 次，所以是一个常量的执行时间，跟 n 的规模无关。
2. 第二段代码时间复杂度是O(n)；第三段代码的时间复杂度是O(n*n)。

综合这三段代码的时间复杂度，我们取其中最大的量级。所以，整段代码的时间复杂度就为 O(n*n)。也就是说：总的时间复杂度就等于量级最大的那段代码的时间复杂度。

那我们将这个规律抽象成公式就是：如果 T1(n)=O(f(n))，T2(n)=O(g(n))；那么 T(n)=T1(n)+T2(n)=max(O(f(n)), O(g(n))) =O(max(f(n), g(n)))。

#### 4.2.3 乘法计算时间复杂度

乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积。 落实到具体的代码上，可以把乘法法则看成是嵌套循环，这种会经常看到：

```c
int cal(int n) {
    int ret = 0; 
    int i = 1;
    for (; i < n; ++i) {
        ret = ret + f(i);
    } 
} 

int f(int n) {
    int sum = 0;
    int i = 1;
    for (; i < n; ++i) {
        sum = sum + i;
    } 
    return sum;
}
```

假设 f() 只是一个普通的操作，那第 4～6 行的时间复杂度就是，T1(n) = O(n)。但 f() 函数本身不是一个简单的操作，它的时间复杂度是 T2(n) = O(n)，所以，整个 cal() 函数的时间复杂度就是，T(n) = T1(n) * T2(n) = O(n*n) = O(n^2)。

刚讲了三种复杂度的分析技巧。不过，你并不用刻意去记忆。实际上，复杂度分析这个东西关键在于“熟练”。你只要多看案例，多分析，就能做到“无招胜有招”。

### 4.3 时间复杂度分类

常见的时间复杂度从低到高依次为：

1. O(1): 常数时间复杂度，无论输入规模多大，算法的运行时间都不变。 
2. O(log n): 对数时间复杂度，问题规模逐步减半,例如二分查找算法。 
3. O(n): 线性时间复杂度，例如遍历数组。 
4. O(n log n): 线性对数时间复杂度，例如归并排序和快速排序的平均情况。 
5. O(n^k): k次方时间复杂度,例如K层嵌套循环 
6. O(2^n): 指数时间复杂度，例如解决背包问题的暴力算法。 
7. O(n!): 阶乘时间复杂度，例如解决旅行商问题的暴力算法。


### 4.6 多项式时间复杂度

1. O(1) 常数阶

O(1) 只是常量级时间复杂度的一种表示方法，并不是指只执行了一行代码。只要代码的执行时间不随 n 的增大而增长，这样代码的时间复杂度我们都记作 O(1)。或者说，一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)。

2. O(logn)、O(nlogn) 对数阶

对数阶时间复杂度非常常见，同时也是最难分析的一种时间复杂度。通过一个例子来说明一下。

```c
i=1;
while (i <= n) {
    i = i * 2;
}
```

从代码中可以看出，变量 i 的值从 1 开始取，每循环一次就乘以 2。当大于 n 时，循环结束。还记得高中学过的等比数列吗？实际上，变量 i 的取值就是一个等比数列。这段代码的时间复杂度就是 O(log 2^n)。

现在，把代码稍微改下，你再看看，这段代码的时间复杂度是多少？

```c
i=1;
while (i <= n) {
    i = i * 3;
}
```

很简单就能看出来，这段代码的时间复杂度为 O(log 3^n)。

实际上，不管是以 2 为底、以 3 为底，还是以 10 为底，我们可以把所有对数阶的时间复杂度都记为 O(logn)。

基于我们前面的一个理论：在采用大 O 标记复杂度的时候，可以忽略系数，即 O(Cf(n)) = O(f(n))。所以，O(log2n) 就等于 O(log3n)。因此，在对数阶时间复杂度的表示方法里，我们忽略对数的“底”，统一表示为 O(logn)。

3. O(m+n)、O(m*n)

O(m+n)、O(m*n)：再来讲一种跟前面都不一样的时间复杂度，代码的复杂度由两个数据的规模来决定。

```c
int cal(int m, int n) {
  int sum_1 = 0;
  int i = 1;
  for (; i < m; ++i) {
    sum_1 = sum_1 + i;
  }
 
  int sum_2 = 0;
  int j = 1;
  for (; j < n; ++j) {
    sum_2 = sum_2 + j;
  }
 
  return sum_1 + sum_2;
}
```

从代码中可以看出，m 和 n 是表示两个数据规模。我们无法事先评估 m 和 n 谁的量级大，所以我们在表示复杂度的时候，就不能简单地利用加法法则，省略掉其中一个。所以，上面代码的时间复杂度就是 O(m+n)。

针对这种情况，原来的加法法则就不正确了，我们需要将加法规则改为：T1(m) + T2(n) = O(f(m) + g(n))。但是乘法法则继续有效：T1(m)*T2(n) = O(f(m) * f(n))。

## 05.什么是空间复杂度

### 5.1 空间复杂度介绍

时间复杂度的全称是渐进时间复杂度，表示算法的执行时间与数据规模之间的增长关系。

类比一下，空间复杂度全称就是渐进空间复杂度（asymptotic space complexity），表示算法的存储空间与数据规模之间的增长关系。

复杂度也叫渐进复杂度，包括时间复杂度和空间复杂度，用来分析算法执行效率与数据规模之间的增长关系，可以粗略地表示，越高阶复杂度的算法，执行效率越低。常见的复杂度并不多，从低阶到高阶有：O(1)、O(logn)、O(n)、O(nlogn)、O(n^2)。

### 5.2 空间复杂度定义

空间复杂度涉及的空间类型有：

1. 输入空间： 存储输入数据所需的空间大小；
2. 暂存空间： 算法运行过程中，存储所有中间变量和对象等数据所需的空间大小；
3. 输出空间： 算法运行返回时，存储输出数据所需的空间大小；

通常情况下，空间复杂度指在输入数据大小为 N 时，算法运行所使用的「暂存空间」+「输出空间」的总体大小。

### 5.3 暂存空间指什么

算法使用的内存空间分为三类：

指令空间：编译后，程序指令所使用的内存空间。

数据空间：算法中的各项变量使用的空间，包括：声明的常量、变量、动态数组、动态对象等使用的内存空间。

```c
struct Node {
    int val;
    Node *next;
    Node(int x) : val(x), next(NULL) {}
};
 
void algorithm(int N) {
    int num = N;              // 变量
    int nums[N];              // 动态数组
    Node* node = new Node(N); // 动态对象
}
```

栈帧空间：程序调用函数是基于栈实现的，函数在调用期间，占用常量大小的栈帧空间，直至返回后释放。如以下代码所示，在循环中调用函数，每轮调用 test() 返回后，栈帧空间已被释放，因此空间复杂度仍为 O(1)。

```c
int test() {
    return 0;
}
 
void algorithm(int N) {
    for (int i = 0; i < N; i++) {
        test();
    }
}
```

栈帧空间的累计常出现于递归调用。如以下代码所示，通过递归调用，会同时存在 N 个未返回的函数 algorithm() ，此时累计使用 O(N) 大小的栈帧空间。

```c
int algorithm(int N) {
    if (N <= 1) return 1;
    return algorithm(N - 1) + 1;
}
```

### 5.4 符号表示的含义

通常情况下，空间复杂度统计算法在 “最差情况” 下使用的空间大小，以体现算法运行所需预留的空间量，使用符号 O 表示。

最差情况有两层含义，分别为「最差输入数据」、算法运行中的「最差运行点」。

最差输入数据：

当 N≤10 时，数组 nums 的长度恒定为 10 ，空间复杂度为 O(10) = O(1)；当 N > 10 时，数组 nums 长度为 N ，空间复杂度为 O(N) ；因此，空间复杂度应为最差输入数据情况下的 O(N) 。

最差运行点：

在执行 nums = [0] * 10 时，算法仅使用 O(1) 大小的空间；而当执行 nums = [0] * N 时，算法使用 O(N) 的空间；因此，空间复杂度应为最差运行点的 O(N) 。

```c
void algorithm(int N) {
    int num = 5;           // O(1)
    vector<int> nums(10);  // O(1)
    if (N > 10) {
        nums.resize(N);    // O(N)
    }
}
```

根据从小到大排列，常见的算法空间复杂度有：O(1) < O(logN) < O(N) < O(N^2) < O(2^N)

### 5.5 常数O(1)案例

普通常量、变量、对象、元素数量与输入数据大小 N 无关的集合，皆使用常数大小的空间。

```c
void algorithm(int N) {
    int num = 0;
    int nums[10000];
    Node* node = new Node(0);
    unordered_map<int, string> dic;
    dic.emplace(0, "0");
}
```

如以下代码所示，虽然函数 test() 调用了 N 次，但每轮调用后 test() 已返回，无累计栈帧空间使用，因此空间复杂度仍为 O(1) 。

```c
void algorithm(int N) {
    for (int i = 0; i < N; i++) {
        test();
    }
}
```

### 5.6 线性O(N)案例

元素数量与 N 呈线性关系的任意类型集合（常见于一维数组、链表、哈希表等），皆使用线性大小的空间。

```c
void algorithm(int N) {
    int nums_1[N];
    int nums_2[N / 2 + 1];
 
    vector<Node*> nodes;
    for (int i = 0; i < N; i++) {
        nodes.push_back(new Node(i));
    }
 
    unordered_map<int, string> dic;
    for (int i = 0; i < N; i++) {
        dic.emplace(i, to_string(i));
    }
}
```

如下图与代码所示，此递归调用期间，会同时存在 N 个未返回的 algorithm() 函数，因此使用 O(N) 大小的栈帧空间。

```c
int algorithm(int N) {
    if (N <= 1) return 1;
    return algorithm(N - 1) + 1;
}
```

### 5.7 平方O(N^2)案例

元素数量与 N 呈平方关系的任意类型集合（常见于矩阵），皆使用平方大小的空间。

```c
void algorithm(int N) {
    vector<vector<int>> num_matrix;
    for (int i = 0; i < N; i++) {
        vector<int> nums;
        for (int j = 0; j < N; j++) {
            nums.push_back(0);
        }
        num_matrix.push_back(nums);
    }
 
    vector<vector<Node*>> node_matrix;
    for (int i = 0; i < N; i++) {
        vector<Node*> nodes;
        for (int j = 0; j < N; j++) {
            nodes.push_back(new Node(j));
        }
        node_matrix.push_back(nodes);
    }
}
```

如下图与代码所示，递归调用时同时存在 N 个未返回的 algorithm() 函数，使用 O(N) 栈帧空间；每层递归函数中声明了数组，平均长度为 N/2 , 使用 O(N) 空间；因此总体空间复杂度为 O(N^2) 。

```
int algorithm(int N) {
    if (N <= 0) return 0;
    int nums[N];
    return algorithm(N - 1);
}
```

### 5.8 指数O(2^N)案例

指数阶常见于二叉树、多叉树。例如，高度为 N 的「满二叉树」的节点数量为 2^N，占用 O(2^N) 大小的空间；同理，高度为 N 的「满 m 叉树」的节点数量为 m^N，占用 O(m^N) = O(2^N) 大小的空间。

### 5.9 对数O(logN)案例

对数阶常出现于分治算法的栈帧空间累计、数据类型转换等，例如：

1）快速排序 ，平均空间复杂度为 Θ(logN) ，最差空间复杂度为 O(N) 。拓展知识：通过应用 Tail Call Optimization ，可以将快速排序的最差空间复杂度限定至 O(N)。

2）数字转化为字符串 ，设某正整数为 N ，则字符串的空间复杂度为 O(logN) 。推导如下：正整数 N 的位数为 log(10,N)，即转化的字符串长度为 log(10,N) ，因此空间复杂度为 O(logN)

## 06.最好和最坏分析

### 6.1 复杂度分析概念

复杂度分析的4个概念

- 1.最坏情况时间复杂度：代码在最理想情况下执行的时间复杂度。
- 2.最好情况时间复杂度：代码在最坏情况下执行的时间复杂度。
- 3.平均时间复杂度：用代码在所有情况下执行的次数的加权平均值表示。
- 4.均摊时间复杂度：在代码执行的所有复杂度情况中绝大部分是低级别的复杂度，个别情况是高级别复杂度且发生具有时序关系时，可以将个别高级别复杂度均摊到低级别复杂度上。基本上均摊结果就等于低级别复杂度。

为何引入这4个概念？

- 1.同一段代码在不同情况下时间复杂度会出现量级差异，为了更全面，更准确的描述代码的时间复杂度，所以引入这4个概念。
- 2.代码复杂度在不同情况下出现量级差别时才需要区别这四种复杂度。大多数情况下，是不需要区别分析它们的。

### 6.2 最好情况复杂度

最好情况时间复杂度：在最理想的情况下，执行这段代码的时间复杂度。就像接下来讲到的，在最理想的情况下，要查找的变量 x 正好是数组的第一个元素，这个时候对应的时间复杂度就是最好情况时间复杂度。

```c
// n 表示数组 array 的长度
int find(int[] array, int n, int x) {
  int i = 0;
  int pos = -1;
  for (; i < n; ++i) {
    if (array[i] == x) {
       pos = i;
       break;
    }
  }
  return pos;
}
```

如果数组中第一个元素正好是要查找的变量x，那就不需要继续遍历剩下的n-1个数据了，那时间复杂度就是 O(1)。这个就是最好情况复杂度！

### 6.3 最坏情况复杂度

最坏情况时间复杂度：在最糟糕的情况下，执行这段代码的时间复杂度。就像接下来举的那个例子，如果数组中没有要查找的变量 x，我们需要把整个数组都遍历一遍才行，所以这种最糟糕情况下对应的时间复杂度就是最坏情况时间复杂度。

```c
// n 表示数组 array 的长度
int find(int[] array, int n, int x) {
  int i = 0;
  int pos = -1;
  for (; i < n; ++i) {
    if (array[i] == x) {
       pos = i;
       break;
    }
  }
  return pos;
}
```

但如果数组中不存在变量 x，那我们就需要把整个数组都遍历一遍，时间复杂度就成了 O(n)。

### 6.4 平均情况复杂度

最好情况时间复杂度和最坏情况时间复杂度对应的都是极端情况下的代码复杂度，发生的概率其实并不大。为了更好地表示平均情况下的复杂度，需要引入另一个概念：平均时间复杂度。

平均时间复杂度又该怎么分析呢？还是借助刚才查找变量 x 的例子来给你解释。

要查找的变量 x 在数组中的位置，有 n+1 种情况：在数组的 0～n-1 位置中和不在数组中。我们把每种情况下，查找需要遍历的元素个数累加起来，然后再除以 n+1，就可以得到需要遍历的元素个数的平均值，即：

![image](https://upload-images.jianshu.io/upload_images/4432347-376b3802d243115a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

时间复杂度的大 O 标记法中，可以省略掉系数、低阶、常量，所以，咱们把刚刚这个公式简化之后，得到的平均时间复杂度就是 O(n)。
  - 这个结论虽然是正确的，但是计算过程稍微有点儿问题。我们刚讲的这 n+1 种情况，出现的概率并不是一样的。我带你具体分析一下。（这里要稍微用到一点儿概率论的知识，不过非常简单，你不用担心。）
- 我们知道，要查找的变量 x，要么在数组里，要么就不在数组里。
  - 这两种情况对应的概率统计起来很麻烦，为了方便你理解，我们假设在数组中与不在数组中的概率都为 1/2。另外，要查找的数据出现在 0～n-1 这 n 个位置的概率也是一样的，为 1/n。所以，根据概率乘法法则，要查找的数据出现在 0～n-1 中任意位置的概率就是 1/(2n)。
  - 因此，前面的推导过程中存在的最大问题就是，没有将各种情况发生的概率考虑进去。如果我们把每种情况发生的概率也考虑进去，那平均时间复杂度的计算过程就变成了这样：
  - ![image](https://upload-images.jianshu.io/upload_images/4432347-4d84341b0c3023a5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
  - 这个值就是概率论中的加权平均值，也叫作期望值，所以平均时间复杂度的全称应该叫加权平均时间复杂度或者期望时间复杂度。
  - 引入概率之后，前面那段代码的加权平均值为 (3n+1)/4。用大 O 表示法来表示，去掉系数和常量，这段代码的加权平均时间复杂度仍然是 O(n)。
- 你可能会说，平均时间复杂度分析好复杂啊，还要涉及概率论的知识。
  - 实际上，在大多数情况下，我们并不需要区分最好、最坏、平均情况时间复杂度三种情况。像我们上一节课举的那些例子那样，很多时候，我们使用一个复杂度就可以满足需求了。只有同一块代码在不同的情况下，时间复杂度有量级的差距，我们才会使用这三种复杂度表示法来区分。



### 6.5 均摊情况复杂度
- 讲一个更加高级的概念，均摊时间复杂度，以及它对应的分析方法，摊还分析（或者叫平摊分析）。
  - 均摊时间复杂度，听起来跟平均时间复杂度有点儿像。对于初学者来说，这两个概念确实非常容易弄混。我前面说了，大部分情况下，我们并不需要区分最好、最坏、平均三种复杂度。平均复杂度只在某些特殊情况下才会用到，而均摊时间复杂度应用的场景比它更加特殊、更加有限。
- 例子2：
    ```
     // array 表示一个长度为 n 的数组
     // 代码中的 array.length 就等于 n
     int[] array = new int[n];
     int count = 0;
     
     void insert(int val) {
        if (count == array.length) {
           int sum = 0;
           for (int i = 0; i < array.length; ++i) {
              sum = sum + array[i];
           }
           array[0] = sum;
           count = 1;
        }
     
        array[count] = val;
        ++count;
     }
    ```
  - 这段代码实现了一个往数组中插入数据的功能。当数组满了之后，也就是代码中的 count == array.length 时，我们用 for 循环遍历数组求和，并清空数组，将求和之后的 sum 值放到数组的第一个位置，然后再将新的数据插入。但如果数组一开始就有空闲空间，则直接将数据插入数组。
- 先用我们刚讲到的三种时间复杂度的分析方法来分析一下：
  - 最理想的情况下，数组中有空闲空间，我们只需要将数据插入到数组下标为 count 的位置就可以了，所以最好情况时间复杂度为 O(1)。
  - 最坏的情况下，数组中没有空闲空间了，我们需要先做一次数组的遍历求和，然后再将数据插入，所以最坏情况时间复杂度为 O(n)。
  - 那平均时间复杂度是多少呢？答案是O(1)。我们还是可以通过前面讲的概率论的方法来分析：假设数组的长度是 n，根据数据插入的位置的不同，我们可以分为n种情况，每种情况的时间复杂度是O(1)。除此之外，还有一种“额外”的情况，就是在数组没有空闲空间时插入一个数据，这个时候的时间复杂度是 O(n)。而且，这 n+1 种情况发生的概率一样，都是1/(n+1)。所以，根据加权平均的计算方法，我们求得的平均时间复杂度就是：
  - ![image](https://upload-images.jianshu.io/upload_images/4432347-bdabf0cb690765a0.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)
- 这个例子里的平均复杂度分析其实并不需要这么复杂，不需要引入概率论的知识。
  - 这是为什么呢？我们先来对比一下这个insert()的例子和前面那个find()的例子，你就会发现这两者有很大差别。
  - 首先，find() 函数在极端情况下，复杂度才为 O(1)。但 insert() 在大部分情况下，时间复杂度都为 O(1)。只有个别情况下，复杂度才比较高，为 O(n)。这是 insert()第一个区别于 find() 的地方。
  - 再来看第二个不同的地方。对于 insert() 函数来说，O(1) 时间复杂度的插入和 O(n) 时间复杂度的插入，出现的频率是非常有规律的，而且有一定的前后时序关系，一般都是一个 O(n) 插入之后，紧跟着 n-1 个 O(1) 的插入操作，循环往复。
  - 所以，针对这样一种特殊场景的复杂度分析，我们并不需要像之前讲平均复杂度分析方法那样，找出所有的输入情况及相应的发生概率，然后再计算加权平均值。
  - 针对这种特殊的场景，我们引入了一种更加简单的分析方法：摊还分析法，通过摊还分析得到的时间复杂度我们起了一个名字，叫**均摊时间复杂度**。
- 那究竟如何使用摊还分析法来分析算法的均摊时间复杂度呢？
  - 还是继续看在数组中插入数据的这个例子。每一次 O(n) 的插入操作，都会跟着 n-1 次 O(1) 的插入操作，所以把耗时多的那次操作均摊到接下来的 n-1 次耗时少的操作上，均摊下来，这一组连续的操作的均摊时间复杂度就是 O(1)。这就是均摊分析的大致思路。你都理解了吗？
  - 均摊时间复杂度和摊还分析应用场景比较特殊，所以我们并不会经常用到。为了方便你理解、记忆，我这里简单总结一下它们的应用场景。如果你遇到了，知道是怎么回事儿就行了。
  - 对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上。而且，在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度。
  - 尽管很多数据结构和算法书籍都花了很大力气来区分平均时间复杂度和均摊时间复杂度，但其实我个人认为，均摊时间复杂度就是一种特殊的平均时间复杂度，我们没必要花太多精力去区分它们。你最应该掌握的是它的分析方法，摊还分析。至于分析出来的结果是叫平均还是叫均摊，这只是个说法，并不重要。


### 参考博客

如何进行算法时间复杂度和空间复杂度分析：https://juejin.cn/post/7408631611040792616



